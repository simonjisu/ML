{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from utils_nn import softmax, cross_entropy_error, sigmoid\n",
    "sys.path.insert(0, '../GD/')\n",
    "from GD_common import numerical_gradient\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **단순 신경망 구현**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class simpleNet(object):\n",
    "    def __init__(self):\n",
    "        self.W = np.random.normal(size=(2,3))\n",
    "        \n",
    "    def predict(self, x):\n",
    "        return np.dot(x, self.W)\n",
    "    \n",
    "    def loss(self, x, t):\n",
    "        z = self.predict(x)\n",
    "        y = softmax(z)\n",
    "        loss = cross_entropy_error(y, t)\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.47210107, -1.07798534,  0.85648856],\n",
       "       [-1.54253597, -1.10336889,  0.32830708]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([0.6, 0.9])\n",
    "t = np.array([0, 0, 1])\n",
    "nn = simpleNet()\n",
    "nn.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.10502173, -1.6398232 ,  0.80936951])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = nn.predict(x)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6592859352182034"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.loss(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = lambda w: nn.loss(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07169653, -0.55800035,  0.48630382],\n",
       "       [ 0.10754479, -0.83700053,  0.72945573]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dW = numerical_gradient(f, nn.W)\n",
    "dW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2층 신경망 학습**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fig1](./figs/NN_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(그림 과 같은 건 아님)\n",
    "* Input Size: m\n",
    "* Hidden Size: h\n",
    "* Output Size: o\n",
    "$$ X_{(batch,\\ m)} \\cdot W1_{(m,\\ h)} + B1_{(batch,\\ h)} \\rightarrow A1_{(batch,\\ h)} $$\n",
    "$$ sigmoid(A1_{(batch,\\ h)}) \\rightarrow Z1_{(batch,\\ h)}$$\n",
    "$$ Z1_{(batch,\\ h)} \\cdot W1_{(h,\\ o)} + B1_{(batch,\\ o)} \\rightarrow A2_{(batch,\\ o)} $$\n",
    "$$ \\sigma(A2_{(batch,\\ o)}) \\rightarrow Y_{(batch,\\ o)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dataset.mnist import load_mnist\n",
    "from two_layer_nn import TwoLayer\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "#highper parameter\n",
    "epoch_num = 1\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "alpha = 0.1  # learning rate\n",
    "epsilon = 1e-6\n",
    "\n",
    "# 1에폭당 반복 수\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "nn = TwoLayer(input_size=784, hidden_size=100, output_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trian acc: 0.09750 | test acc: 0.09740\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-ae18c1b2930c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# gradient 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/gitproject/ML/NeuralNetwork/two_layer_nn.py\u001b[0m in \u001b[0;36mnum_gradient\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerical_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/gitproject/ML/GD/GD_common.py\u001b[0m in \u001b[0;36mnumerical_gradient\u001b[0;34m(f, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_val\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mfxh2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# f(x-h)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfxh1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfxh2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/gitproject/ML/NeuralNetwork/two_layer_nn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(W)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnum_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mloss_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/gitproject/ML/NeuralNetwork/two_layer_nn.py\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcross_entropy_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/gitproject/ML/NeuralNetwork/two_layer_nn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0ma2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for epoch in range(epoch_num):\n",
    "    # get mini batch: \n",
    "    batch_mask = np.random.choice(train_size, batch_size) # shuffle 효과\n",
    "    x_batch = x_train[batch_mask]\n",
    "    y_batch = y_train[batch_mask]\n",
    "    \n",
    "    # gradient 계산\n",
    "    grad = nn.num_gradient(x_batch, y_batch)\n",
    "    \n",
    "    # update\n",
    "    for key in ['W1', 'b1', 'W2', 'b2']:\n",
    "        nn.params[key] = nn.params[key] - alpha * grad[key]\n",
    "    \n",
    "    # record\n",
    "    loss = nn.loss(x_batch, y_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    # 1에폭당 정확도 계산\n",
    "    if epoch % iter_per_epoch == 0:\n",
    "        train_acc = nn.accuracy(x_train, y_train)\n",
    "        test_acc = nn.accuracy(x_test, y_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print('trian acc: {0:.5f} | test acc: {1:.5f}'.format(train_acc, test_acc))\n",
    "        \n",
    "    # stop point\n",
    "    if epoch > 10:\n",
    "        stop_point = np.sum(np.diff(np.array(train_loss_list[i-11:])) < epsilon)\n",
    "        if stop_point == 10:\n",
    "            print(epoch)\n",
    "            break\n",
    "\n",
    "end = time.time()\n",
    "print('total time:', (start - end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **backpropagation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **연쇄법칙의 원리**\n",
    "합성 함수의 미분은 합성 함수를 구성하는 각 함수의 미분의 곱으로 나타낼 수 있다.\n",
    "\n",
    "$$\\begin{cases} z = t^2\\\\ t = x + y \\end{cases}$$\n",
    "\n",
    "위 식의 미분을 나타내면\n",
    "$$ \\frac{\\partial{z}}{\\partial{x}} = \\frac{\\partial{z}}{\\partial{t}} \\cdot \\frac{\\partial{t}}{\\partial{x}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial{z}}{\\partial{t}} = 2t\\\\ \\frac{\\partial{t}}{\\partial{x}}=1 $$\n",
    "\n",
    "$$\\therefore\\  \\frac{\\partial{z}}{\\partial{x}} = \\frac{\\partial{z}}{\\partial{t}} \\cdot \\frac{\\partial{t}}{\\partial{x}} = 2t \\cdot 1 = 2(x+y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial{L}}{\\partial{W}} = \\frac{\\partial{L}}{\\partial{Y}} \\cdot \\frac{\\partial{Y}}{\\partial{W}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"./figs/NN_add.png\" alt=\"Drawing\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "덧셈 노드는 들어온 신호를 그대로 보낸다 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./figs/NN_multiply.png\" alt=\"Drawing\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "곱셈 노드는 들어온 신호에 서로 바뀐 입력신호 값을 곱해서 하류로 보낸다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **sigmoid 계층**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ y = \\frac{1}{1+\\exp(-x)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![](./figs/NN_sigmoid_forward.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./figs/NN_sigmoid_back.png)\n",
    "![](./figs/NN_sigmoid_back2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **역전파 1단계 ( / )**\n",
    "\"/\" 연산은 입력변수 x를 $\\frac{1}{x}$ 로 바꿔준다. 즉 $ f1(x) = \\frac{1}{x}$ 가 된다.\n",
    "\n",
    "미분을 하게 되면 $\\frac{\\partial{f1}}{\\partial{x}} = -\\frac{1}{x^2} = -y^2$가 되서 입력신호를 하류로 보낸다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### **역전파 2단계 ( + )**\n",
    "\"+\" 연산은 신호를 그대로 하류로 흘러 보낸다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **역전파 3단계 (exp)**\n",
    "\"exp\"연산은 $f2(x) = exp(x)$ 이며, 미분도 $\\frac{\\partial{f2}}{\\partial{x}} = exp(x)$ 로 그대로 곱해서 하류로 보낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **역전파 4단계 ( x )**\n",
    "\"$\\times$\"연산은 서로 바뀐 입력신호의 값을 곱해서 보낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "따라서,\n",
    "![](./figs/NN_sigmoid_last.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최종적으로 시그모이드의 역전파 출력값은  \n",
    "\n",
    "$$ \\frac{\\partial{L}}{\\partial{y}}y^{2}\\exp(-x)\\\\ \n",
    "= \\frac{\\partial{L}}{\\partial{y}} \\frac{1}{[1+\\exp(-x)]^2}\\exp(-x) \\\\\n",
    "= \\frac{\\partial{L}}{\\partial{y}} \\frac{1}{1+\\exp(-x)} \\frac{\\exp(-x)}{1+\\exp(-x)} \\\\\n",
    "= \\frac{\\partial{L}}{\\partial{y}}y(1-y)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Affine / Softmax 계층**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Affine Transform**\n",
    "기하학에서 신경망 순전파 때 수행하는 행렬의 내적, Affine 계층은 어파인 변환을 수행 처리하는 계층임\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sympy미분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sympy\n",
    "from sympy.tensor.array import *\n",
    "# Juypter 노트북에서 수학식의 LaTeX 표현을 위해 필요함\n",
    "sympy.init_printing(use_unicode=False, wrap_line=False, no_global=True, use_latex='mathjax')\n",
    "from sympy.matrices import Matrix\n",
    "w11, w12, w21, w22, w31, w32 = sympy.symbols(('w11', 'w12', 'w21', 'w22', 'w31', 'w32'))\n",
    "x1, x2 = sympy.symbols(('x1', 'x2'))\n",
    "y1 = sympy.Function('y1')(w11*x1 + w12*x2)\n",
    "y2 = sympy.Function('y2')(w21*x1 + w22*x2)\n",
    "y3 = sympy.Function('y3')(w31*x1 + w32*x2)\n",
    "Y = Matrix([y1, y2, y3])\n",
    "W = Matrix([[w11, w12],\n",
    "            [w21, w22],\n",
    "            [w31, w32]])\n",
    "X = Matrix([x1, x2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\left[\\begin{matrix}\\operatorname{y_{1}}{\\left (w_{11} x_{1} + w_{12} x_{2} \\right )}\\\\\\operatorname{y_{2}}{\\left (w_{21} x_{1} + w_{22} x_{2} \\right )}\\\\\\operatorname{y_{3}}{\\left (w_{31} x_{1} + w_{32} x_{2} \\right )}\\end{matrix}\\right]$$"
      ],
      "text/plain": [
       "[y1(w11*x1 + w12*x2)]\n",
       "[                   ]\n",
       "[y2(w21*x1 + w22*x2)]\n",
       "[                   ]\n",
       "[y3(w31*x1 + w32*x2)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\left[\\begin{matrix}w_{11} & w_{12}\\\\w_{21} & w_{22}\\\\w_{31} & w_{32}\\end{matrix}\\right]$$"
      ],
      "text/plain": [
       "[w11  w12]\n",
       "[        ]\n",
       "[w21  w22]\n",
       "[        ]\n",
       "[w31  w32]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\left[\\begin{matrix}x_{1}\\\\x_{2}\\end{matrix}\\right]$$"
      ],
      "text/plain": [
       "[x1]\n",
       "[  ]\n",
       "[x2]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\left[\\begin{matrix}\\left[\\begin{matrix}x_{1} \\left. \\frac{d}{d \\xi_{1}} \\operatorname{y_{1}}{\\left (\\xi_{1} \\right )} \\right|_{\\substack{ \\xi_{1}=w_{11} x_{1} + w_{12} x_{2} }}\\\\0\\\\0\\end{matrix}\\right] & \\left[\\begin{matrix}x_{2} \\left. \\frac{d}{d \\xi_{1}} \\operatorname{y_{1}}{\\left (\\xi_{1} \\right )} \\right|_{\\substack{ \\xi_{1}=w_{11} x_{1} + w_{12} x_{2} }}\\\\0\\\\0\\end{matrix}\\right]\\\\\\left[\\begin{matrix}0\\\\x_{1} \\left. \\frac{d}{d \\xi_{1}} \\operatorname{y_{2}}{\\left (\\xi_{1} \\right )} \\right|_{\\substack{ \\xi_{1}=w_{21} x_{1} + w_{22} x_{2} }}\\\\0\\end{matrix}\\right] & \\left[\\begin{matrix}0\\\\x_{2} \\left. \\frac{d}{d \\xi_{1}} \\operatorname{y_{2}}{\\left (\\xi_{1} \\right )} \\right|_{\\substack{ \\xi_{1}=w_{21} x_{1} + w_{22} x_{2} }}\\\\0\\end{matrix}\\right]\\\\\\left[\\begin{matrix}0\\\\0\\\\x_{1} \\left. \\frac{d}{d \\xi_{1}} \\operatorname{y_{3}}{\\left (\\xi_{1} \\right )} \\right|_{\\substack{ \\xi_{1}=w_{31} x_{1} + w_{32} x_{2} }}\\end{matrix}\\right] & \\left[\\begin{matrix}0\\\\0\\\\x_{2} \\left. \\frac{d}{d \\xi_{1}} \\operatorname{y_{3}}{\\left (\\xi_{1} \\right )} \\right|_{\\substack{ \\xi_{1}=w_{31} x_{1} + w_{32} x_{2} }}\\end{matrix}\\right]\\end{matrix}\\right]$$"
      ],
      "text/plain": [
       "[[   /  d            \\|                    ]  [   /  d            \\|                    ]]\n",
       "[[x1*|-----(y1(xi_1))||                    ]  [x2*|-----(y1(xi_1))||                    ]]\n",
       "[[   \\dxi_1          /|xi_1=w11*x1 + w12*x2]  [   \\dxi_1          /|xi_1=w11*x1 + w12*x2]]\n",
       "[[                                         ]  [                                         ]]\n",
       "[[                    0                    ]  [                    0                    ]]\n",
       "[[                                         ]  [                                         ]]\n",
       "[[                    0                    ]  [                    0                    ]]\n",
       "[                                                                                        ]\n",
       "[[                    0                    ]  [                    0                    ]]\n",
       "[[                                         ]  [                                         ]]\n",
       "[[   /  d            \\|                    ]  [   /  d            \\|                    ]]\n",
       "[[x1*|-----(y2(xi_1))||                    ]  [x2*|-----(y2(xi_1))||                    ]]\n",
       "[[   \\dxi_1          /|xi_1=w21*x1 + w22*x2]  [   \\dxi_1          /|xi_1=w21*x1 + w22*x2]]\n",
       "[[                                         ]  [                                         ]]\n",
       "[[                    0                    ]  [                    0                    ]]\n",
       "[                                                                                        ]\n",
       "[[                    0                    ]  [                    0                    ]]\n",
       "[[                                         ]  [                                         ]]\n",
       "[[                    0                    ]  [                    0                    ]]\n",
       "[[                                         ]  [                                         ]]\n",
       "[[   /  d            \\|                    ]  [   /  d            \\|                    ]]\n",
       "[[x1*|-----(y3(xi_1))||                    ]  [x2*|-----(y3(xi_1))||                    ]]\n",
       "[[   \\dxi_1          /|xi_1=w31*x1 + w32*x2]  [   \\dxi_1          /|xi_1=w31*x1 + w32*x2]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "derive_by_array(Y, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\left[\\begin{matrix}\\left[\\begin{matrix}w_{11} x_{1}\\\\w_{11} x_{2}\\end{matrix}\\right] & \\left[\\begin{matrix}w_{12} x_{1}\\\\w_{12} x_{2}\\end{matrix}\\right]\\\\\\left[\\begin{matrix}w_{21} x_{1}\\\\w_{21} x_{2}\\end{matrix}\\right] & \\left[\\begin{matrix}w_{22} x_{1}\\\\w_{22} x_{2}\\end{matrix}\\right]\\\\\\left[\\begin{matrix}w_{31} x_{1}\\\\w_{31} x_{2}\\end{matrix}\\right] & \\left[\\begin{matrix}w_{32} x_{1}\\\\w_{32} x_{2}\\end{matrix}\\right]\\end{matrix}\\right]$$"
      ],
      "text/plain": [
       "[[w11*x1]  [w12*x1]]\n",
       "[[      ]  [      ]]\n",
       "[[w11*x2]  [w12*x2]]\n",
       "[                  ]\n",
       "[[w21*x1]  [w22*x1]]\n",
       "[[      ]  [      ]]\n",
       "[[w21*x2]  [w22*x2]]\n",
       "[                  ]\n",
       "[[w31*x1]  [w32*x1]]\n",
       "[[      ]  [      ]]\n",
       "[[w31*x2]  [w32*x2]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp = tensorproduct(W, X)\n",
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\left ( 3, \\quad 2, \\quad 2, \\quad 1\\right )$$"
      ],
      "text/plain": [
       "(3, 2, 2, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1)\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$$\\left[\\begin{matrix}w_{11} x_{1} + w_{12} x_{2}\\\\w_{21} x_{1} + w_{22} x_{2}\\\\w_{31} x_{1} + w_{32} x_{2}\\end{matrix}\\right]$$"
      ],
      "text/plain": [
       "[w11*x1 + w12*x2]\n",
       "[               ]\n",
       "[w21*x1 + w22*x2]\n",
       "[               ]\n",
       "[w31*x1 + w32*x2]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_prod = tensorcontraction(tp, (1,2))\n",
    "print(dot_prod.shape)\n",
    "dot_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$\\left[\\begin{matrix}\\left[\\begin{matrix}x_{1}\\\\0\\\\0\\end{matrix}\\right] & \\left[\\begin{matrix}x_{2}\\\\0\\\\0\\end{matrix}\\right]\\\\\\left[\\begin{matrix}0\\\\x_{1}\\\\0\\end{matrix}\\right] & \\left[\\begin{matrix}0\\\\x_{2}\\\\0\\end{matrix}\\right]\\\\\\left[\\begin{matrix}0\\\\0\\\\x_{1}\\end{matrix}\\right] & \\left[\\begin{matrix}0\\\\0\\\\x_{2}\\end{matrix}\\right]\\end{matrix}\\right]$$"
      ],
      "text/plain": [
       "[[x1]  [x2]]\n",
       "[[  ]  [  ]]\n",
       "[[0 ]  [0 ]]\n",
       "[[  ]  [  ]]\n",
       "[[0 ]  [0 ]]\n",
       "[          ]\n",
       "[[0 ]  [0 ]]\n",
       "[[  ]  [  ]]\n",
       "[[x1]  [x2]]\n",
       "[[  ]  [  ]]\n",
       "[[0 ]  [0 ]]\n",
       "[          ]\n",
       "[[0 ]  [0 ]]\n",
       "[[  ]  [  ]]\n",
       "[[0 ]  [0 ]]\n",
       "[[  ]  [  ]]\n",
       "[[x1]  [x2]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "derive_by_array(dot_prod, W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Softmax-with-loss 계층**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "softmax 와 cross-entropy 를 합친것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
