{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is it really ture about $\\theta = 0.6$ from our evidence \"HHTHT\"?? \n",
    "\n",
    "But someone may thought $\\theta=0.5$, how can we merge previous knowledge in our trials?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Rule\n",
    "\n",
    "$$\\begin{aligned} Posterior &= \\dfrac{Likelihood \\times Prior Knowledge}{Normalizing Constant}\\\\\n",
    "P(\\theta \\vert D) &= \\dfrac{P(D \\vert \\theta)P(\\theta)}{P(D)}\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(D)$ is already happened probability. so we see it as a constant then\n",
    "\n",
    "$$P(\\theta \\vert D) \\propto P(D \\vert \\theta)P(\\theta)$$\n",
    "\n",
    "* $P(D \\vert \\theta) = \\theta^{a_H}(1-\\theta)^{a_T}$\n",
    "* $P(\\theta)$ = ???\n",
    "\n",
    "we need to present the prior knowledge well for $P(\\theta)$.\n",
    "\n",
    "Here use **Beta distribution**: [wiki](https://ko.wikipedia.org/wiki/%EB%B2%A0%ED%83%80_%EB%B6%84%ED%8F%AC)\n",
    "\n",
    "\n",
    "$$\\begin{aligned}\n",
    "P(\\theta) &= \\dfrac{\\theta^{\\alpha-1}(1-\\theta)^{\\beta-1} }{B(\\alpha, \\beta)} \\\\\n",
    "B(\\alpha, \\beta) &= \\dfrac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha+\\beta)},\\ \\Gamma(\\alpha)=(\\alpha-1)!\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![beta_dist](./figs/Beta_distribution_cdf.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, \n",
    "\n",
    "$$\\begin{aligned}\n",
    "P(\\theta \\vert D) \n",
    "& \\propto P(D \\vert \\theta)P(\\theta) \\\\\n",
    "& \\propto \\theta^{a_H}(1-\\theta)^{a_T} \\theta^{\\alpha-1}(1-\\theta)^{\\beta-1} \\\\ \n",
    "&= \\theta^{a_H+\\alpha-1} (1-\\theta)^{a_T+\\beta-1} \\\\\n",
    "\\end{aligned}$$\n",
    "\n",
    "$B(\\alpha, \\beta)$ is not defined by $\\theta$ so can ignore it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum a Posteriori Estimation\n",
    "\n",
    "In MLE, find $\\theta$ using, $P(D \\vert \\theta) = \\theta^{a_H}(1-\\theta)^{a_T}$\n",
    "\n",
    "$$\\hat{\\theta} = \\underset{\\theta}{\\arg \\max}\\ P(\\theta \\vert D) = \\dfrac{a_H}{a_H+a_T}$$\n",
    "\n",
    "Now in MAP. we find $\\theta$ using, $P(\\theta \\vert D) \\propto \\theta^{a_H+\\alpha-1} (1-\\theta)^{a_T+\\beta-1}$\n",
    "\n",
    "$$\\hat{\\theta} = \\underset{\\theta}{\\arg \\max}\\ P(D \\vert \\theta) = \\dfrac{a_H + \\alpha - 1}{a_H + \\alpha + a_T + \\beta -2}$$\n",
    "\n",
    "관점이 다름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different? No, when we do a lot of trials ($a_H, a_T$ become larger), the effectness of $\\alpha, \\beta$ will be small at the end. However, when $a_H, a_T$ are small, **prior information** will affect $\\theta$ and have a important role.\n",
    "\n",
    "How to define $\\alpha, \\beta$ ? ;) try it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
